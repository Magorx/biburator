{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PyQt6.QtWidgets import (\n",
    "    QMainWindow, QApplication, QWidget,\n",
    "    QLabel, QCheckBox, QComboBox,\n",
    "    QPushButton, QTextEdit,\n",
    "    QLineEdit, QSpinBox, QDoubleSpinBox, QSlider,\n",
    "    QVBoxLayout, QHBoxLayout, QGridLayout, QFormLayout, QWIDGETSIZE_MAX\n",
    ")\n",
    "from PyQt6.QtCore import Qt, QSize, QPoint\n",
    "from PyQt6.QtGui import QPixmap, QPalette, QColor, QImage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, no_show=False):\n",
    "    plt.imshow(image)\n",
    "    xticks = plt.xticks()\n",
    "    yticks = plt.yticks()\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    if not no_show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kingcake/Venvs/neuro/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:coremltools:TensorFlow version 2.11.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.10.0 is the most recent version that has been tested.\n",
      "WARNING:coremltools:Torch version 2.0.0.dev20230118 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "from python_coreml_stable_diffusion.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    prompt='a photo of an astronaut riding a horse on mars', i='models/coreml-stable-diffusion-2-base_original_packages', o='output', seed=96, model_version='stabilityai/stable-diffusion-2-base', compute_unit='ALL', scheduler=None, num_inference_steps=50, guidance_scale=7.5, pickle=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python_coreml_stable_diffusion.pipeline:Initializing PyTorch pipe for reference configuration\n",
      "Fetching 16 files: 100%|██████████| 16/16 [00:00<00:00, 4473.33it/s]\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Loading Core ML pipe\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Removed PyTorch pipe to reduce peak memory consumption\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Loading Core ML models in memory from models/coreml-stable-diffusion-2-base_original_packages\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-2-base_original_packages/Stable_Diffusion_version_stabilityai_stable-diffusion-2-base_text_encoder.mlpackage\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m load_model(args)\n",
      "File \u001b[0;32m~/Repositories/biburator/python_coreml_stable_diffusion/pipeline.py:580\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    576\u001b[0m     user_specified_scheduler \u001b[39m=\u001b[39m SCHEDULER_MAP[\n\u001b[1;32m    577\u001b[0m         args\u001b[39m.\u001b[39mscheduler]\u001b[39m.\u001b[39mfrom_config(pytorch_pipe\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mconfig)\n\u001b[1;32m    579\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mLoading Core ML pipe\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 580\u001b[0m coreml_pipe \u001b[39m=\u001b[39m get_coreml_pipe(pytorch_pipe\u001b[39m=\u001b[39;49mpytorch_pipe,\n\u001b[1;32m    581\u001b[0m                               mlpackages_dir\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mi,\n\u001b[1;32m    582\u001b[0m                               model_version\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mmodel_version,\n\u001b[1;32m    583\u001b[0m                               compute_unit\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mcompute_unit,\n\u001b[1;32m    584\u001b[0m                               scheduler_override\u001b[39m=\u001b[39;49muser_specified_scheduler)\n\u001b[1;32m    586\u001b[0m \u001b[39mreturn\u001b[39;00m coreml_pipe\n",
      "File \u001b[0;32m~/Repositories/biburator/python_coreml_stable_diffusion/pipeline.py:428\u001b[0m, in \u001b[0;36mget_coreml_pipe\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[39m# Load Core ML models\u001b[39;00m\n\u001b[1;32m    427\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading Core ML models in memory from \u001b[39m\u001b[39m{\u001b[39;00mmlpackages_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 428\u001b[0m coreml_pipe_kwargs\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m    429\u001b[0m     model_name: _load_mlpackage(\n\u001b[1;32m    430\u001b[0m         model_name,\n\u001b[1;32m    431\u001b[0m         mlpackages_dir,\n\u001b[1;32m    432\u001b[0m         model_version,\n\u001b[1;32m    433\u001b[0m         compute_unit,\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m     \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m model_names_to_load\n\u001b[1;32m    436\u001b[0m })\n\u001b[1;32m    437\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDone.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    439\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mInitializing Core ML pipe for image generation\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Repositories/biburator/python_coreml_stable_diffusion/pipeline.py:429\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[39m# Load Core ML models\u001b[39;00m\n\u001b[1;32m    427\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading Core ML models in memory from \u001b[39m\u001b[39m{\u001b[39;00mmlpackages_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    428\u001b[0m coreml_pipe_kwargs\u001b[39m.\u001b[39mupdate({\n\u001b[0;32m--> 429\u001b[0m     model_name: _load_mlpackage(\n\u001b[1;32m    430\u001b[0m         model_name,\n\u001b[1;32m    431\u001b[0m         mlpackages_dir,\n\u001b[1;32m    432\u001b[0m         model_version,\n\u001b[1;32m    433\u001b[0m         compute_unit,\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m     \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m model_names_to_load\n\u001b[1;32m    436\u001b[0m })\n\u001b[1;32m    437\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDone.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    439\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mInitializing Core ML pipe for image generation\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Repositories/biburator/python_coreml_stable_diffusion/coreml_model.py:99\u001b[0m, in \u001b[0;36m_load_mlpackage\u001b[0;34m(submodule_name, mlpackages_dir, model_version, compute_unit)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(mlpackage_path):\n\u001b[1;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msubmodule_name\u001b[39m}\u001b[39;00m\u001b[39m CoreML model doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist at \u001b[39m\u001b[39m{\u001b[39;00mmlpackage_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m CoreMLModel(mlpackage_path, compute_unit)\n",
      "File \u001b[0;32m~/Repositories/biburator/python_coreml_stable_diffusion/coreml_model.py:30\u001b[0m, in \u001b[0;36mCoreMLModel.__init__\u001b[0;34m(self, model_path, compute_unit)\u001b[0m\n\u001b[1;32m     27\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading \u001b[39m\u001b[39m{\u001b[39;00mmodel_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mMLModel(\n\u001b[1;32m     31\u001b[0m     model_path, compute_units\u001b[39m=\u001b[39;49mct\u001b[39m.\u001b[39;49mComputeUnit[compute_unit])\n\u001b[1;32m     32\u001b[0m load_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\n\u001b[1;32m     33\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDone. Took \u001b[39m\u001b[39m{\u001b[39;00mload_time\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Venvs/neuro/lib/python3.10/site-packages/coremltools/models/model.py:331\u001b[0m, in \u001b[0;36mMLModel.__init__\u001b[0;34m(self, model, is_temp_package, mil_program, skip_model_load, compute_units, weights_dir)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_temp_package \u001b[39m=\u001b[39m is_temp_package\n\u001b[1;32m    330\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights_dir \u001b[39m=\u001b[39m _try_get_weights_dir_path(model)\n\u001b[0;32m--> 331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__proxy__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_framework_error \u001b[39m=\u001b[39m _get_proxy_and_spec(\n\u001b[1;32m    332\u001b[0m         model, compute_units, skip_model_load\u001b[39m=\u001b[39;49mskip_model_load,\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, _Model_pb2\u001b[39m.\u001b[39mModel):\n\u001b[1;32m    335\u001b[0m     \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mWhichOneof(\u001b[39m'\u001b[39m\u001b[39mType\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmlProgram\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Venvs/neuro/lib/python3.10/site-packages/coremltools/models/model.py:143\u001b[0m, in \u001b[0;36m_get_proxy_and_spec\u001b[0;34m(filename, compute_units, skip_model_load)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mNone\u001b[39;00m, specification, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m (_MLModelProxy(filename, compute_units\u001b[39m.\u001b[39;49mname), specification, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    144\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    145\u001b[0m     _warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    146\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou will not be able to run predict() on this Core ML model.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m Underlying exception message was: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    149\u001b[0m         \u001b[39mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = load_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def callback(i, t, latents):\n",
    "#     # show the image\n",
    "#     image = (model.decode_latents(latents)[0] * 255).astype(np.uint8)\n",
    "\n",
    "#     qt_image = QImage(image.shape[1], image.shape[0], QImage.Format.Format_RGB888)\n",
    "#     for x in range(image.shape[1]):\n",
    "#         for y in range(image.shape[0]):\n",
    "#             qt_image.setPixel(x, y, QColor(image[y, x, 0], image[y, x, 1], image[y, x, 2]).rgb())\n",
    "\n",
    "#     show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret = model(\n",
    "#     \"a ((perfect)) circle\",\n",
    "#     seed=100,\n",
    "#     num_inference_steps=2,\n",
    "#     callback=callback\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt6.QtWidgets import (\n",
    "    QMainWindow, QApplication, QWidget,\n",
    "    QLabel, QCheckBox, QComboBox,\n",
    "    QPushButton, QTextEdit,\n",
    "    QLineEdit, QSpinBox, QDoubleSpinBox, QSlider,\n",
    "    QVBoxLayout, QHBoxLayout, QGridLayout, QFormLayout, QProgressBar, QWIDGETSIZE_MAX\n",
    ")\n",
    "from PyQt6.QtCore import Qt, QSize, QPoint\n",
    "from PyQt6.QtGui import QPixmap, QPalette, QColor, QImage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "def np_to_pixmap(image):\n",
    "    # convert numpy array to QPixmap\n",
    "    image = np.uint8(image * 255)\n",
    "    qt_image = QImage(image.shape[1], image.shape[0], QImage.Format.Format_RGB888)\n",
    "    for x in range(image.shape[1]):\n",
    "        for y in range(image.shape[0]):\n",
    "            qt_image.setPixel(x, y, QColor(image[y, x, 0], image[y, x, 1], image[y, x, 2]).rgb())\n",
    "    \n",
    "    return QPixmap.fromImage(qt_image)\n",
    "\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "\n",
    "    def __init__(self, ui):\n",
    "        super(MainWindow, self).__init__()\n",
    "        self.ui = ui\n",
    "\n",
    "        self.setWindowTitle(\"Biburator\")\n",
    "\n",
    "        grid = QGridLayout()\n",
    "\n",
    "        widget = QWidget()\n",
    "        widget.setLayout(grid)\n",
    "        self.setCentralWidget(widget)\n",
    "\n",
    "        pixmap = QPixmap(512, 512)\n",
    "        pixmap.fill(QColor(215, 215, 215))\n",
    "        self.image_label = QLabel(\"This is a label\")\n",
    "        self.image_label.setPixmap(pixmap)\n",
    "        self.image_label.setBaseSize(pixmap.size())\n",
    "\n",
    "        self.progress_bar = QProgressBar()\n",
    "\n",
    "        self.prompt_input = QTextEdit()\n",
    "        self.prompt_input.setPlaceholderText(\"Enter promt here\")\n",
    "\n",
    "        self.steps_input = QLineEdit(\"30\")\n",
    "        self.steps_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.steps_label = QLabel(\"Steps\")\n",
    "\n",
    "        self.guidence_input = QLineEdit(\"7.5\")\n",
    "        self.guidence_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.guidence_label = QLabel(\"Guidence\")\n",
    "\n",
    "        self.seed_input = QLineEdit(\"-1\")\n",
    "        self.seed_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.seed_label = QLabel(\"Seed\")\n",
    "\n",
    "        self.count_input = QLineEdit(\"1\")\n",
    "        self.count_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.count_label = QLabel(\"Count\")\n",
    "\n",
    "        self.generate_button = QPushButton(\"Generate\")\n",
    "        self.generate_button.clicked.connect(self.button_clicked)\n",
    "\n",
    "        opts = [\n",
    "            [\n",
    "                self.steps_label,\n",
    "                self.steps_input,\n",
    "                self.guidence_label,\n",
    "                self.guidence_input,\n",
    "                self.seed_label,\n",
    "                self.seed_input,\n",
    "                self.count_label,\n",
    "                self.count_input,\n",
    "            ],\n",
    "        ]\n",
    "\n",
    "        max_opts = max([len(opt) for opt in opts])\n",
    "        px = max_opts\n",
    "        cur = 0\n",
    "\n",
    "        # add widgets to layout\n",
    "        grid.addWidget(self.image_label, 0, 0, px, px, Qt.AlignmentFlag.AlignCenter)\n",
    "        cur += px\n",
    "\n",
    "        grid.addWidget(self.progress_bar, cur, 0, 1, px)\n",
    "        cur += 1\n",
    "\n",
    "        grid.addWidget(self.prompt_input, cur, 0, 1, px)\n",
    "        cur += 1\n",
    "\n",
    "        grid.addWidget(self.generate_button, cur, 0, 1, px)\n",
    "        cur += 1\n",
    "\n",
    "        for i, opt in enumerate(opts):\n",
    "            for j, widget in enumerate(opt):\n",
    "                grid.addWidget(widget, i + cur, j, 1, 1)\n",
    "        cur += 1\n",
    "\n",
    "        self.inited = False\n",
    "        self.setFixedWidth(pixmap.width())\n",
    "\n",
    "        self.is_generating = False\n",
    "    \n",
    "    def set_max_progress(self, max_progress):\n",
    "        self.max_progress = max_progress\n",
    "        self.progress_bar.setRange(0, max_progress)\n",
    "    \n",
    "    def initial_center(self):\n",
    "        self.center()\n",
    "    \n",
    "    def center(self):\n",
    "        qr = self.frameGeometry()\n",
    "        cp = self.screen().availableGeometry().center()\n",
    "\n",
    "        qr.moveCenter(cp)\n",
    "        self.move(qr.topLeft())\n",
    "\n",
    "    def init(self):\n",
    "        if self.inited:\n",
    "            return\n",
    "        self.inited = True\n",
    "\n",
    "        self.center()\n",
    "\n",
    "        self.setMaximumSize(QWIDGETSIZE_MAX, QWIDGETSIZE_MAX)\n",
    "        self.setMinimumSize(0, 0)\n",
    "\n",
    "    def resizeEvent(self, event):\n",
    "        if not self.inited:\n",
    "            self.init()\n",
    "    \n",
    "    def enter_generating_mode(self):\n",
    "        if self.is_generating:\n",
    "            return False\n",
    "\n",
    "        self.is_generating = True\n",
    "        # self.generate_button.setEnabled(False)\n",
    "        return True\n",
    "    \n",
    "    def exit_generating_mode(self):\n",
    "        self.is_generating = False\n",
    "        # self.generate_button.setEnabled(True)\n",
    "    \n",
    "    def button_clicked(self):\n",
    "        if not self.enter_generating_mode():\n",
    "            return\n",
    "\n",
    "        prompt = self.prompt_input.toPlainText()\n",
    "        steps = int(self.steps_input.text())\n",
    "        guidence = float(self.guidence_input.text())\n",
    "        seed = int(self.seed_input.text())\n",
    "        count = int(self.count_input.text())\n",
    "\n",
    "        if seed == -1:\n",
    "            seed = randint(0, 2**32 - 1)\n",
    "        \n",
    "        self.ui.logger.info(f\"Prompt: {prompt}, guidence: {guidence}, seed: {seed}, count: {count}\")\n",
    "        Thread(target=self.generate_thread, args=(prompt, steps, guidence, seed, count)).start()\n",
    "    \n",
    "    def create_generation_step_callback(self):\n",
    "        def callback(i, t, latents):\n",
    "            image = self.ui.model.decode_latents(latents)[0]\n",
    "\n",
    "            pixmap = np_to_pixmap(image)\n",
    "            self.image_label.setPixmap(pixmap)\n",
    "\n",
    "            # self.progress_bar.setValue(i)\n",
    "\n",
    "        return callback\n",
    "    \n",
    "    def generate(self, prompt, steps, guidence, seed):\n",
    "        self.ui.logger.info(f\"Prompt: {prompt}, guidence: {guidence}, seed: {seed}\")\n",
    "        image = self.ui.model(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=guidence,\n",
    "            seed=seed,\n",
    "            callback=self.create_generation_step_callback()\n",
    "        )\n",
    "    \n",
    "    def generate_thread(self, prompt, steps, guidence, seed, count):\n",
    "        for i in range(count):\n",
    "            self.set_max_progress(steps)\n",
    "            self.generate(prompt, steps, guidence, seed)\n",
    "        self.exit_generating_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UI:\n",
    "    app = QApplication([])\n",
    "\n",
    "    def __init__(self, model, logger) -> None:\n",
    "        self.window = MainWindow(self)\n",
    "        self.window.show()\n",
    "\n",
    "        self.model = model\n",
    "        self.logger = logger\n",
    "        \n",
    "    def exec(self):\n",
    "        UI.app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui = UI(model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python_coreml_stable_diffusion.pipeline:Prompt: cat, guidence: 7.5, seed: 682539326, count: 1\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Prompt: cat, guidence: 7.5, seed: 682539326\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Setting random seed to 682539326\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "ui.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0dab42545ccb40627b9d96de210b5df64244cfa1d263bd957e771b19ff93e57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
