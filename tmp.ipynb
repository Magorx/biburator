{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PyQt6.QtWidgets import (\n",
    "    QMainWindow, QApplication, QWidget,\n",
    "    QLabel, QCheckBox, QComboBox,\n",
    "    QPushButton, QTextEdit,\n",
    "    QLineEdit, QSpinBox, QDoubleSpinBox, QSlider,\n",
    "    QVBoxLayout, QHBoxLayout, QGridLayout, QFormLayout, QWIDGETSIZE_MAX\n",
    ")\n",
    "from PyQt6.QtCore import Qt, QSize, QPoint\n",
    "from PyQt6.QtGui import QPixmap, QPalette, QColor, QImage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, no_show=False):\n",
    "    plt.imshow(image)\n",
    "    xticks = plt.xticks()\n",
    "    yticks = plt.yticks()\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    if not no_show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kingcake/Venvs/neuro/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:coremltools:TensorFlow version 2.11.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.10.0 is the most recent version that has been tested.\n",
      "WARNING:coremltools:Torch version 2.0.0.dev20230118 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "from python_coreml_stable_diffusion.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    prompt='a photo of an astronaut riding a horse on mars', i='models/coreml-stable-diffusion-2-base_original_packages', o='output', seed=96, model_version='stabilityai/stable-diffusion-2-base', compute_unit='ALL', scheduler=None, num_inference_steps=50, guidance_scale=7.5, pickle=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python_coreml_stable_diffusion.pipeline:Initializing PyTorch pipe for reference configuration\n",
      "Fetching 16 files: 100%|██████████| 16/16 [00:00<00:00, 8914.57it/s]\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Removed PyTorch pipe to reduce peak memory consumption\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Loading Core ML models in memory from models/coreml-stable-diffusion-2-base_original_packages\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-2-base_original_packages/Stable_Diffusion_version_stabilityai_stable-diffusion-2-base_text_encoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 19.1 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-2-base_original_packages/Stable_Diffusion_version_stabilityai_stable-diffusion-2-base_unet.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 127.1 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-2-base_original_packages/Stable_Diffusion_version_stabilityai_stable-diffusion-2-base_vae_decoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 14.4 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Done.\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Initializing Core ML pipe for image generation\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Stable Diffusion configured to generate 512x512 images\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Done.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def callback(i, t, latents):\n",
    "#     # show the image\n",
    "#     image = (model.decode_latents(latents)[0] * 255).astype(np.uint8)\n",
    "\n",
    "#     qt_image = QImage(image.shape[1], image.shape[0], QImage.Format.Format_RGB888)\n",
    "#     for x in range(image.shape[1]):\n",
    "#         for y in range(image.shape[0]):\n",
    "#             qt_image.setPixel(x, y, QColor(image[y, x, 0], image[y, x, 1], image[y, x, 2]).rgb())\n",
    "\n",
    "#     show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret = model(\n",
    "#     \"a ((perfect)) circle\",\n",
    "#     seed=100,\n",
    "#     num_inference_steps=2,\n",
    "#     callback=callback\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt6.QtWidgets import (\n",
    "    QMainWindow, QApplication, QWidget,\n",
    "    QLabel, QCheckBox, QComboBox,\n",
    "    QPushButton, QTextEdit,\n",
    "    QLineEdit, QSpinBox, QDoubleSpinBox, QSlider,\n",
    "    QVBoxLayout, QHBoxLayout, QGridLayout, QFormLayout, QProgressBar, QWIDGETSIZE_MAX\n",
    ")\n",
    "from PyQt6.QtCore import Qt, QSize, QPoint\n",
    "from PyQt6.QtGui import QPixmap, QPalette, QColor, QImage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "def np_to_pixmap(image):\n",
    "    # convert numpy array to QPixmap\n",
    "    image = np.uint8(image * 255)\n",
    "    qt_image = QImage(image.shape[1], image.shape[0], QImage.Format.Format_RGB888)\n",
    "    for x in range(image.shape[1]):\n",
    "        for y in range(image.shape[0]):\n",
    "            qt_image.setPixel(x, y, QColor(image[y, x, 0], image[y, x, 1], image[y, x, 2]).rgb())\n",
    "    \n",
    "    return QPixmap.fromImage(qt_image)\n",
    "\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "\n",
    "    def __init__(self, ui):\n",
    "        super(MainWindow, self).__init__()\n",
    "        self.ui = ui\n",
    "\n",
    "        self.setWindowTitle(\"Biburator\")\n",
    "\n",
    "        grid = QGridLayout()\n",
    "\n",
    "        widget = QWidget()\n",
    "        widget.setLayout(grid)\n",
    "        self.setCentralWidget(widget)\n",
    "\n",
    "        pixmap = QPixmap(512, 512)\n",
    "        pixmap.fill(QColor(215, 215, 215))\n",
    "        self.image_label = QLabel(\"This is a label\")\n",
    "        self.image_label.setPixmap(pixmap)\n",
    "        self.image_label.setBaseSize(pixmap.size())\n",
    "\n",
    "        self.progress_bar = QProgressBar()\n",
    "\n",
    "        self.prompt_input = QTextEdit()\n",
    "        self.prompt_input.setPlaceholderText(\"Enter promt here\")\n",
    "\n",
    "        self.steps_input = QLineEdit(\"30\")\n",
    "        self.steps_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.steps_label = QLabel(\"Steps\")\n",
    "\n",
    "        self.guidence_input = QLineEdit(\"7.5\")\n",
    "        self.guidence_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.guidence_label = QLabel(\"Guidence\")\n",
    "\n",
    "        self.seed_input = QLineEdit(\"-1\")\n",
    "        self.seed_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.seed_label = QLabel(\"Seed\")\n",
    "\n",
    "        self.count_input = QLineEdit(\"1\")\n",
    "        self.count_input.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.count_label = QLabel(\"Count\")\n",
    "\n",
    "        self.generate_button = QPushButton(\"Generate\")\n",
    "        self.generate_button.clicked.connect(self.button_clicked)\n",
    "\n",
    "        opts = [\n",
    "            [\n",
    "                self.steps_label,\n",
    "                self.steps_input,\n",
    "                self.guidence_label,\n",
    "                self.guidence_input,\n",
    "                self.seed_label,\n",
    "                self.seed_input,\n",
    "                self.count_label,\n",
    "                self.count_input,\n",
    "            ],\n",
    "        ]\n",
    "\n",
    "        max_opts = max([len(opt) for opt in opts])\n",
    "        px = max_opts\n",
    "        cur = 0\n",
    "\n",
    "        # add widgets to layout\n",
    "        grid.addWidget(self.image_label, 0, 0, px, px, Qt.AlignmentFlag.AlignCenter)\n",
    "        cur += px\n",
    "\n",
    "        grid.addWidget(self.progress_bar, cur, 0, 1, px)\n",
    "        cur += 1\n",
    "\n",
    "        grid.addWidget(self.prompt_input, cur, 0, 1, px)\n",
    "        cur += 1\n",
    "\n",
    "        grid.addWidget(self.generate_button, cur, 0, 1, px)\n",
    "        cur += 1\n",
    "\n",
    "        for i, opt in enumerate(opts):\n",
    "            for j, widget in enumerate(opt):\n",
    "                grid.addWidget(widget, i + cur, j, 1, 1)\n",
    "        cur += 1\n",
    "\n",
    "        self.inited = False\n",
    "        self.setFixedWidth(pixmap.width())\n",
    "\n",
    "        self.is_generating = False\n",
    "    \n",
    "    def set_max_progress(self, max_progress):\n",
    "        self.max_progress = max_progress\n",
    "        self.progress_bar.setRange(0, max_progress)\n",
    "    \n",
    "    def initial_center(self):\n",
    "        self.center()\n",
    "    \n",
    "    def center(self):\n",
    "        qr = self.frameGeometry()\n",
    "        cp = self.screen().availableGeometry().center()\n",
    "\n",
    "        qr.moveCenter(cp)\n",
    "        self.move(qr.topLeft())\n",
    "\n",
    "    def init(self):\n",
    "        if self.inited:\n",
    "            return\n",
    "        self.inited = True\n",
    "\n",
    "        self.center()\n",
    "\n",
    "        self.setMaximumSize(QWIDGETSIZE_MAX, QWIDGETSIZE_MAX)\n",
    "        self.setMinimumSize(0, 0)\n",
    "\n",
    "    def resizeEvent(self, event):\n",
    "        if not self.inited:\n",
    "            self.init()\n",
    "    \n",
    "    def enter_generating_mode(self):\n",
    "        if self.is_generating:\n",
    "            return False\n",
    "\n",
    "        self.is_generating = True\n",
    "        # self.generate_button.setEnabled(False)\n",
    "        return True\n",
    "    \n",
    "    def exit_generating_mode(self):\n",
    "        self.is_generating = False\n",
    "        # self.generate_button.setEnabled(True)\n",
    "    \n",
    "    def button_clicked(self):\n",
    "        if not self.enter_generating_mode():\n",
    "            return\n",
    "\n",
    "        prompt = self.prompt_input.toPlainText()\n",
    "        steps = int(self.steps_input.text())\n",
    "        guidence = float(self.guidence_input.text())\n",
    "        seed = int(self.seed_input.text())\n",
    "        count = int(self.count_input.text())\n",
    "\n",
    "        if seed == -1:\n",
    "            seed = randint(0, 2**32 - 1)\n",
    "        \n",
    "        self.ui.logger.info(f\"Prompt: {prompt}, guidence: {guidence}, seed: {seed}, count: {count}\")\n",
    "        Thread(target=self.generate_thread, args=(prompt, steps, guidence, seed, count)).start()\n",
    "    \n",
    "    def create_generation_step_callback(self):\n",
    "        def callback(i, t, latents):\n",
    "            image = self.ui.model.decode_latents(latents)[0]\n",
    "\n",
    "            pixmap = np_to_pixmap(image)\n",
    "            self.image_label.setPixmap(pixmap)\n",
    "\n",
    "            # self.progress_bar.setValue(i)\n",
    "\n",
    "        return callback\n",
    "    \n",
    "    def generate(self, prompt, steps, guidence, seed):\n",
    "        self.ui.logger.info(f\"Prompt: {prompt}, guidence: {guidence}, seed: {seed}\")\n",
    "        image = self.ui.model(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=guidence,\n",
    "            seed=seed,\n",
    "            callback=self.create_generation_step_callback()\n",
    "        )\n",
    "    \n",
    "    def generate_thread(self, prompt, steps, guidence, seed, count):\n",
    "        for i in range(count):\n",
    "            self.set_max_progress(steps)\n",
    "            self.generate(prompt, steps, guidence, seed)\n",
    "        self.exit_generating_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UI:\n",
    "    app = QApplication([])\n",
    "\n",
    "    def __init__(self, model, logger) -> None:\n",
    "        self.window = MainWindow(self)\n",
    "        self.window.show()\n",
    "\n",
    "        self.model = model\n",
    "        self.logger = logger\n",
    "        \n",
    "    def exec(self):\n",
    "        UI.app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui = UI(model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python_coreml_stable_diffusion.pipeline:Prompt: cat, guidence: 7.5, seed: 682539326, count: 1\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Prompt: cat, guidence: 7.5, seed: 682539326\n",
      "INFO:python_coreml_stable_diffusion.pipeline:Setting random seed to 682539326\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "ui.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0dab42545ccb40627b9d96de210b5df64244cfa1d263bd957e771b19ff93e57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
